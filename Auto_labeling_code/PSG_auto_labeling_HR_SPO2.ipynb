{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pandas as pd\n",
    "from scipy import stats, signal\n",
    "from scipy.signal import butter\n",
    "import scipy\n",
    "from pyedflib import highlevel\n",
    "from path import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in data from edf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drive data link: \n",
    "# EE481: https://drive.google.com/drive/folders/1vh3GeBGvYB9J9DZ8yG7Fvvvbqj-QnXb2\n",
    "# EE464: https://drive.google.com/drive/folders/1wVDt9dwh_dQE2izJJMP19tKpQne9xzr3\n",
    "# EE461: https://drive.google.com/drive/folders/1-BFvnQYDbcQW_0UnB_lVnqPhoGRh2aeA\n",
    "\n",
    "dpath = ['../re-synchornize/EP2_PSG_EE481_EB_DEV6751_1621093397.edf' \n",
    "         ,'../re-synchornize/EP2_PSG_EE464_EB_DEV755b_1620834065.edf' \n",
    "         ,'../re-synchornize/EP2_PSG_EE461_EB_DEV6751_1620745140.edf']\n",
    "\n",
    "\n",
    "subject_list = [str(Path(dpath[i]).name).split('_')[2] for i in range(len(dpath))]\n",
    "print(subject_list)\n",
    "\n",
    "channel_indices = [22,23,24] # SpO2, ECG I, ECG II\n",
    "signals, signal_headers, _ = highlevel.read_edf(dpath[0],ch_nrs=channel_indices)\n",
    "signal_name = []\n",
    "srate_values = []\n",
    "winlength = [10,15,30] #10, 15, and 30 seconds window\n",
    "stride = [10,15,30]\n",
    "\n",
    "for i in range(len(signals)):\n",
    "    signal_name.append(signal_headers[i]['label'])\n",
    "    srate_values.append(signal_headers[i]['sample_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SpO2 stride, SPO2 array of moving window, and window length of both HR and SPO2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPO2 stride. 1D list. [10*10, 15*10, 30*10]\n",
    "spo2_stride_list = [stride[i]*srate_values[0] for i in range(len(stride))]\n",
    "    \n",
    "# Winlength for both HR and SPO2. 2D list.\n",
    "# row: different winlength | col: difference in sampling rate\n",
    "winlength_list = [[winlength[0]*srate_values[i] for i in range(len(winlength))],\n",
    "                  [winlength[1]*srate_values[i] for i in range(len(winlength))],\n",
    "                  [winlength[2]*srate_values[i] for i in range(len(winlength))]]\n",
    "\n",
    "# SPO2 winonset. 2D list. row: different winlength | col: an array of corresponding winlength\n",
    "SPO2_winonset = [np.arange(0,len(signals[0])-winlength_list[i][0],spo2_stride_list[i]).tolist() for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating SPO2 with 3 different window lengths\n",
    "spo2_mean = []\n",
    "for j in range(len(SPO2_winonset)):\n",
    "    spo2_mean.append([])\n",
    "    for i in range(len(SPO2_winonset[j])):\n",
    "        data_pack = signals[0][int(SPO2_winonset[j][i]):int(SPO2_winonset[j][i]+winlength[0])]\n",
    "        spo2_mean[j].append(np.mean(data_pack))\n",
    "    \n",
    "# Creating spo2_file list that contains time and data\n",
    "spo2_file = []\n",
    "for j in range(len(spo2_mean)):\n",
    "    spo2_file.append([])\n",
    "    for i in range(len(spo2_mean[j])):\n",
    "        spo2_file[j].append([winonset_list[j][i]/srate_values[0],spo2_mean[j][i]])\n",
    "    \n",
    "# Saving spo2 data into csv files\n",
    "for name in subject_list:\n",
    "    os.mkdir(name)\n",
    "    for i, win in enumerate(winlength):\n",
    "        fpath = os.path.join(name,name+'_spo2_label_'+str(win)+'.csv')\n",
    "        np.savetxt(fpath, spo2_file[i], delimiter=\",\", fmt='%10.2f')\n",
    "\n",
    "# np.savetxt(\"EE461/EE461_spo2_label_10s.csv\", spo2_file[0], delimiter=\",\", fmt='%10.2f')\n",
    "# np.savetxt(\"EE461/EE461_spo2_label_15s.csv\", spo2_file[1], delimiter=\",\", fmt='%10.2f')\n",
    "# np.savetxt(\"EE461/EE461_spo2_label_30s.csv\", spo2_file[2], delimiter=\",\", fmt='%10.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heart rate stride and array of moving windows (HR_winonset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered ECG I signal | sampling rate 200Hz\n",
    "upper_f = 3\n",
    "lower_f = 1\n",
    "filt_sig = butter_bandpass_filter(signals[1], lower_f, upper_f, srate_values[1], order=1)\n",
    "\n",
    "# Stride with 10s, 15s, and 30s\n",
    "HR_stride =  [stride[i]*srate_values[1] for i in range(len(stride))]\n",
    "\n",
    "# winonset for heart rate with 10s, 15s, and 30s windows\n",
    "HR_winonset = [np.arange(0,len(signals[1])-winlength_list[i][1],HR_stride[i]).tolist() for i in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Heart Rate\n",
    "hrate = []\n",
    "for i in range(len(HR_winonset)):\n",
    "    hrate.append([])\n",
    "    for win in range(0,len(HR_winonset[i])):\n",
    "        heart_rate, heart_rate_std, _ = compute_heart_rate(sig[HR_winonset[i][win]:HR_winonset[i][win]+time],200)\n",
    "        hrate[i].append(heart_rate)\n",
    "        \n",
    "# Saving heart rate into csv files\n",
    "hrate_file = []\n",
    "for i in range(len(hrate)):\n",
    "    hrate_file.append([])\n",
    "    for j in range(len(hrate[i])):\n",
    "        hrate_file[i].append([winonset_list[i][j],hrate[i][j]])\n",
    "        \n",
    "# Saving Heart rate data into csv files\n",
    "np.savetxt('EE461/EE461_HR_label_10s.csv', hrate_file[0], delimiter=',', fmt='%10.1f')\n",
    "np.savetxt('EE461/EE461_HR_label_15s.csv', hrate_file[1], delimiter=',', fmt='%10.1f')\n",
    "np.savetxt('EE461/EE461_HR_label_30s.csv', hrate_file[2], delimiter=',', fmt='%10.1f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to find peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_peaks(x, scale=None, debug=False):\n",
    "    \"\"\"\n",
    "    https://github.com/ig248/pyampd/blob/master/pyampd/ampd.py\n",
    "    \n",
    "    Find peaks in quasi-periodic noisy signals using AMPD algorithm.\n",
    "    Extended implementation handles peaks near start/end of the signal.\n",
    "    Optimized implementation by Igor Gotlibovych, 2018\n",
    "    @input:\n",
    "        x : ndarray\n",
    "            1-D array on which to find peaks\n",
    "        scale : int, optional\n",
    "            specify maximum scale window size of (2 * scale + 1)\n",
    "        debug : bool, optional\n",
    "            if set to True, return the Local Scalogram Matrix, `LSM`,\n",
    "            weigted number of maxima, 'G',\n",
    "            and scale at which G is maximized, `l`,\n",
    "            together with peak locations\n",
    "    @output:\n",
    "        pks: ndarray\n",
    "            The ordered array of peak indices found in `x`\n",
    "    \"\"\"\n",
    "    x = signal.detrend(x)\n",
    "    N = len(x)\n",
    "    L = N // 2\n",
    "    if scale:\n",
    "        L = min(scale, L)\n",
    "\n",
    "    # create LSM matix\n",
    "    LSM = np.ones((L, N), dtype=bool)\n",
    "    for k in np.arange(1, L + 1):\n",
    "        LSM[k - 1, 0:N - k] &= (x[0:N - k] > x[k:N])  # compare to right neighbours\n",
    "        LSM[k - 1, k:N]     &= (x[k:N] > x[0:N - k])  # compare to left neighbours\n",
    "\n",
    "    # Find scale with most maxima\n",
    "    G = LSM.sum(axis=1)\n",
    "    G = G * np.arange( N // 2, N // 2 - L, -1)  # normalize to adjust for new edge regions\n",
    "    l_scale = np.argmax(G)\n",
    "\n",
    "    # find peaks that persist on all scales up to l\n",
    "    pks_logical = np.min(LSM[0:l_scale, :], axis=0)\n",
    "    pks = np.flatnonzero(pks_logical)\n",
    "    if debug:\n",
    "        return pks, LSM, G, l_scale\n",
    "    return pks\n",
    "\n",
    "def compute_heart_rate(data, srate):\n",
    "    \"\"\"\n",
    "    Compute heart rate from data\n",
    "    @input: \n",
    "            data (ndarray): 1-D array on which to compute the hear rate\n",
    "            srate (float): sampling rate of the data in Hz\n",
    "\n",
    "    @output: \n",
    "            heart_beat_mean (float): mean heart beats per minute in the data segment\n",
    "            heart_beat_std (float): standart deviation of the computed hear beat in the data segment\n",
    "            peaks (ndarray): indices of peak point in data\n",
    "    \"\"\"\n",
    "    peaks = find_peaks(data)\n",
    "    \n",
    "    # remove the first and last peak\n",
    "    peaks = peaks[1:-1] \n",
    "    \n",
    "    # compute the interval between beats\n",
    "    beat_intervals = np.array([ (peaks[i] - peaks[i-1])/(srate*60) for i in range(1,len(peaks))])\n",
    "    \n",
    "    # compute the beats per minute\n",
    "    heart_beats = 1/beat_intervals\n",
    "    heart_beat_mean = np.mean(heart_beats)\n",
    "    heart_beat_std = np.std(heart_beats)\n",
    "\n",
    "    return heart_beat_mean, heart_beat_std, peaks\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=1):\n",
    "    b, a = butter(order, [lowcut, highcut], btype='band',fs=fs)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
